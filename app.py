import os
import gc
import cv2
import json
import torch
import base64
import pickle
import pandas as pd
from PIL import Image
import streamlit as st
from pathlib import Path
from sentence_transformers import SentenceTransformer, util

from dotenv import load_dotenv
from huggingface_hub import login
load_dotenv()
login(token=os.getenv("HFTOKEN"))


device = 'cpu'

# Monkey patch torch.load to always map to CPU
torch_load_old = torch.load
def torch_load_cpu(*args, **kwargs):
    kwargs['map_location'] = torch.device('cpu')
    return torch_load_old(*args, **kwargs)

torch.load = torch_load_cpu

# âœ… ä¸€æ¬¡è¼‰å…¥æ‰€æœ‰æ¨¡å‹ï¼ˆé¿å… OOMï¼‰
@st.cache_resource
def load_models():
    return {
        'minilm': SentenceTransformer('paraphrase-multilingual-MiniLM-L12-v2', device=device),
        'LaBSE': SentenceTransformer('sentence-transformers/LaBSE', device=device),
        'bilingual': SentenceTransformer('am-azadi/bilingual-embedding-small_Fine_Tuned', trust_remote_code=True, device=device),
        'gemma': SentenceTransformer('google/embeddinggemma-300m', device=device),
        'qwen3': SentenceTransformer('tomaarsen/Qwen3-Embedding-0.6B-18-layers', device=device)
    }
model_map = load_models()

# å…¨åŸŸè®Šæ•¸
if "search_history_dict" not in st.session_state:
    st.session_state.search_history_dict = {_tag: {} for _tag in model_map.keys()}

if "search_history_list" not in st.session_state:
    st.session_state.search_history_list = []

# st å¤–å±¤è¨­å®š
st.set_page_config(layout="wide")
st.title("ğŸŒ® Toby å¤šèªè¨€èªæ„æœå°‹ Demo ç³»çµ±")

st.markdown("""
<style>
.stApp {
    color: #0D47A1; /* æ·±è—è‰²å­—é«” */
}

h1, h2, h3 {
    color: #0D47A1; /* æ·±è—æ¨™é¡Œ */
}

.stSlider label {
    color: yellow; /* è¨­å®šæ¨™ç±¤å­—é«”ç‚ºé»ƒè‰² */
}
</style>
""", unsafe_allow_html=True)


@st.cache_data
def get_base64_of_bin_file(bin_file):
    with open(bin_file, 'rb') as f:
        data = f.read()
    return base64.b64encode(data).decode()

def set_png_as_page_bg(png_file, opacity):
    bin_str = get_base64_of_bin_file(png_file)
    page_bg_img = f"""
    <style>
    .stApp {{
        background: linear-gradient(rgba(255,255,255,{opacity}), rgba(255,255,255,{opacity})),
                    url("data:image/png;base64,{bin_str}");
        background-size: cover;
        background-repeat: no-repeat;
        background-attachment: fixed;
    }}
    </style>
    """
    st.markdown(page_bg_img, unsafe_allow_html=True)

opacity = st.slider("é¸æ“‡èƒŒæ™¯æ·¡åº¦ (0.0 = å®Œå…¨é€æ˜, 1.0 = å®Œå…¨ç™½)", 0.0, 1.0, 0.5, 0.01)
set_png_as_page_bg('images/capybara01.png', opacity)
st.write(f"ç›®å‰é€æ˜åº¦ï¼š{opacity}")

# Sidebar UI
st.sidebar.title("ğŸ” å¤šèªè¨€æœå°‹è¨­å®š")
port_num = st.sidebar.number_input("è«‹è¼¸å…¥ Portï¼š", value=8040)
model_name = st.sidebar.selectbox("é¸æ“‡æ¨¡å‹", list(model_map.keys()))
query_mode = st.sidebar.selectbox("æŸ¥è©¢é¡å‹", ['user', 'tag', 'content', 'ç°¡ä»‹', 'è²éŸ³', 'ç°¡ä»‹smol'])
top_k = st.sidebar.number_input("è¼¸å‡ºæ•¸é‡", min_value=1, max_value=100, value=10)
query_text = st.sidebar.text_input("è¼¸å…¥æŸ¥è©¢å­—ä¸²")
search_button = st.sidebar.button("Search")

tab1, tab2, tab3 = st.tabs(
    ["ğŸ¹ èªæ„æŸ¥è©¢ Search", 
     "ğŸ£ å½±ç‰‡è§€è³ View", 
     "ğŸ¦– æ­·å²æŸ¥è©¢ History"],
    width = "stretch"
)

# âœ… è¼‰å…¥ JSON è³‡æ–™ï¼ˆé¿å…æ¯æ¬¡æŸ¥è©¢é‡è®€ï¼‰
@st.cache_data
def load_video_metadata():
    with open("vds/video_metadata.json", "r", encoding="utf-8") as f:
        return json.load(f)
data_json = load_video_metadata()

# âœ… å¿«å– embeddings å’Œ DataFrame
@st.cache_data
def load_embeddings_and_df(query_mode, model_name):
    if query_mode == 'user':
        with open(f'embeddings/members_embeddings_{model_name}.pkl', 'rb') as f:
            ids, emb = pickle.load(f)
        df = pd.read_csv('datas/members.csv')
        df['text'] = df['account'].fillna('') + ' ' + df['nickname'].fillna('')
    elif query_mode == 'tag':
        with open(f'embeddings/tags_embeddings_{model_name}.pkl', 'rb') as f:
            ids, emb = pickle.load(f)
        df = pd.read_csv('datas/posts.csv')
        df['text'] = df['hash_tags'].fillna('')
    elif query_mode == 'content':
        with open(f'embeddings/content_embeddings_{model_name}.pkl', 'rb') as f:
            ids, emb = pickle.load(f)
        df = pd.read_csv('datas/posts.csv')
        df['text'] = df['content'].fillna('')
    else:
        ids, emb, df = [], torch.empty(0), pd.DataFrame()
    
    # âœ… embeddings ç§»åˆ° CPU ä¸€æ¬¡å®Œæˆ
    emb = emb.cpu()
    return ids, emb, df

with tab1:
    st.title("ğŸ” æŸ¥è©¢çµæœ")
    if search_button and query_text.strip():
        # âœ… æª¢æŸ¥æ˜¯å¦å·²æœ‰å¿«å–çš„ query_emb
        if query_text in st.session_state.search_history_dict[model_name]:
            query_emb = st.session_state.search_history_dict[model_name][query_text]
            st.info("ä½¿ç”¨å¿«å–çš„ Query Embedding âœ…")
        else:
            model = model_map[model_name]
            query_emb = model.encode(query_text, convert_to_tensor=True).cpu()
            st.session_state.search_history_dict[model_name][query_text] = query_emb

        results = []
        if query_mode in ['ç°¡ä»‹', 'è²éŸ³', 'ç°¡ä»‹smol']:
            emb_field = f'{query_mode}_{model_name}'
            text_field = query_mode

            for item in data_json:
                emb_list = item.get(emb_field, [])
                if emb_list:
                    emb_tensor = torch.tensor(emb_list, dtype=torch.float32)
                    score = util.cos_sim(query_emb, emb_tensor)[0][0].item()
                    results.append({
                        'æª”å': item['æª”å'],
                        'score': round(score, 4),
                        'text': item[text_field]
                    })

            # æ’åºä¸¦é¡¯ç¤º
            results = sorted(results, key=lambda x: x['score'], reverse=True)[:top_k]
            
            column_config={
                "æª”å": st.column_config.TextColumn("æª”å", width="medium"),
                "score": st.column_config.NumberColumn("ç›¸ä¼¼åº¦", format="%.4f"),
                "text": st.column_config.TextColumn("å…§å®¹", width="large", help="é»æ“Šå¯å±•é–‹å®Œæ•´å…§å®¹"),
            }
            
                
        elif query_mode in ['user', 'tag', 'content']:
            ids, emb, df = load_embeddings_and_df(query_mode, model_name)
            scores = util.cos_sim(query_emb, emb)[0]
            top_indices = scores.argsort(descending=True)[:top_k]

            for i in top_indices:
                idx = int(i)
                results.append({
                    'id': ids[idx],
                    'score': round(float(scores[idx]), 4),
                    'text': df.iloc[idx]['text']
                })
            column_config={
                "id": st.column_config.TextColumn("ID", width="small"),
                "score": st.column_config.NumberColumn("ç›¸ä¼¼åº¦", format="%.4f"),
                "text": st.column_config.TextColumn("å…§å®¹", width="large", help="é»æ“Šå¯å±•é–‹å®Œæ•´å…§å®¹"),
            }
        
        # âœ… é¡¯ç¤ºçµæœè¡¨æ ¼
        if results:
            st.dataframe(
                pd.DataFrame(results),
                column_config = column_config
            )
            if query_mode in ['ç°¡ä»‹', 'è²éŸ³', 'ç°¡ä»‹smol']:
                for i, res in enumerate(results):
                    name = res['æª”å']
                    url = f"http://localhost:{port_num}/{name}.mp4"
                    st.markdown(f'{i}. {url}', unsafe_allow_html=True)            
            

        else:
            st.warning("æ²’æœ‰æ‰¾åˆ°ç›¸é—œçµæœã€‚")

        # âœ… æ›´æ–°æ­·å²ç´€éŒ„åˆ—è¡¨
        st.session_state.search_history_list.append({
            'query_text': query_text,
            'model_name': model_name,
            'query_mode': query_mode,
            'timestamp': pd.Timestamp.now().strftime("%Y-%m-%d %H:%M:%S")
        })

        # âœ… é‡‹æ”¾æš«å­˜å¼µé‡
        del query_emb
        gc.collect()
        torch.cuda.empty_cache()

with tab2:
    st.header("ğŸ’½ æ¸¬è©¦å½±ç‰‡è§€è³")

    # å–å¾—å½±ç‰‡æ¸…å–®
    video_dir = Path("vds/videos")
    video_files = list(video_dir.glob("*.mp4"))
    video_names = [video_f.name for video_f in video_files]

    if not video_files:
        st.warning("æ‰¾ä¸åˆ°å½±ç‰‡æª”æ¡ˆã€‚è«‹ç¢ºèª vds/videos è³‡æ–™å¤¾ä¸­æœ‰ .mp4 æª”æ¡ˆã€‚")
    else:
        # ä¸‹æ‹‰é¸å–®é¸æ“‡å½±ç‰‡
        selected_video_name = st.selectbox("é¸æ“‡å½±ç‰‡", video_names)

        if selected_video_name:
            # è®€å–å½±ç‰‡è³‡è¨Š
            selected_video = f"vds/videos/{selected_video_name}"
            cap = cv2.VideoCapture(str(selected_video))
            if cap.isOpened():
                width = int(cap.get(cv2.CAP_PROP_FRAME_WIDTH))
                height = int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))
                fps = cap.get(cv2.CAP_PROP_FPS)
                frame_count = int(cap.get(cv2.CAP_PROP_FRAME_COUNT))
                duration = frame_count / fps if fps > 0 else 0
                file_size = os.path.getsize(selected_video) / (1024 * 1024)  # MB
                cap.release()
                
            col1, col2, col3 = st.columns(3)
            with col1:
                # é¡¯ç¤ºå½±ç‰‡
                st.header("å½±ç‰‡æ’­æ”¾")
                st.video(str(selected_video))
                
            with col2:
                st.header("å½±ç‰‡è³‡è¨Š")
                st.write(f"ğŸ“ è§£æåº¦ï¼š{width} x {height}")
                st.write(f"ğŸï¸ FPSï¼š{fps:.2f}")
                st.write(f"â±ï¸ æ™‚é•·ï¼š{duration:.2f} ç§’")
                st.write(f"ğŸ’¾ æª”æ¡ˆå¤§å°ï¼š{file_size:.2f} MB")
                
            with col3:
                st.header("éš¨æ‰‹å¯«")
                st.text_area("é€™è£¡å®Œå…¨ä¸æœƒç´€éŒ„")       
            
with tab3:
    st.header("ğŸ“œ æ­·å²æŸ¥è©¢ç´€éŒ„")
    if st.session_state.search_history_list:
        st.dataframe(pd.DataFrame(st.session_state.search_history_list))
        if st.button("æ¸…é™¤æ­·å²ç´€éŒ„"):
            st.session_state.search_history_list.clear()
            st.session_state.search_history_dict.clear()
            st.success("æ­·å²ç´€éŒ„å·²æ¸…é™¤ âœ…")
    else:
        st.info("ç›®å‰æ²’æœ‰æ­·å²ç´€éŒ„ã€‚")

